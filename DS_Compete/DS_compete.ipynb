{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# DS_Comptete\n",
    "- AUTHOR: SungwookLE\n",
    "- DATE: '21.6/29\n",
    "\n",
    "* PROBLEM  \n",
    "1) 아래 코드의 문제점을 적고 해결하라 (한줄추가)\n",
    "    ```\n",
    "    X_train = X_train.reshape((X_train.shape[0],X_train.shape[1],X_train.shape[2],1)) #추가한 코드\n",
    "    X_test = X_test.reshape((X_test.shape[0],X_test.shape[1],X_test.shape[2],1)) #추가한 코드\n",
    "    ```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "BEFORE SHAPE IS (60000, 28, 28)\n",
      "AFTER SHAPE IS (60000, 28, 28, 1)\n",
      "Conv2D:\t(None, 28, 28, 32)\n",
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 303s 5ms/step - loss: 14.5466\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 325s 5ms/step - loss: 14.5463\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 319s 5ms/step - loss: 14.5463\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3614b6bcc0>"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Conv2D,Flatten,MaxPool2D\n",
    "\n",
    "(X_train, y_train), (X_test,y_test) = mnist.load_data()\n",
    "\n",
    "print(\"BEFORE SHAPE IS {}\".format(X_train.shape))\n",
    "X_train = X_train.reshape((X_train.shape[0],X_train.shape[1],X_train.shape[2],1)) #추가한 코드\n",
    "X_test = X_test.reshape((X_test.shape[0],X_test.shape[1],X_test.shape[2],1)) #추가한 코드\n",
    "print(\"AFTER SHAPE IS {}\".format(X_train.shape))\n",
    "\n",
    "model_lenet = Sequential()\n",
    "model_lenet.add(Conv2D(input_shape=(28,28,1),kernel_size=(5,5),strides=(1,1),filters=32,padding='same', activation='relu'))\n",
    "# print('Conv2D:\\t{0}'.format(model_lenet.output_shape))\n",
    "model_lenet.add(MaxPool2D(pool_size=(2,2),strides=(2,2),padding='same'))\n",
    "model_lenet.add(Conv2D(kernel_size=(5,5),strides=(1,1),filters=48,padding='same', activation='relu'))\n",
    "model_lenet.add(MaxPool2D(pool_size=(2,2),strides=(2,2),padding='same'))\n",
    "model_lenet.add(Flatten())\n",
    "model_lenet.add(Dense(256,activation='relu'))\n",
    "model_lenet.add(Dense(84,activation='relu'))\n",
    "model_lenet.add(Dense(10,activation='softmax'))\n",
    "model_lenet.compile(loss='sparse_categorical_crossentropy',optimizer='adam')\n",
    "model_lenet.fit(X_train, y_train, batch_size=32, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=model_lenet.predict(X_test)\n",
    "one_hot_y = tf.one_hot(y_test, 10)\n",
    "out=one_hot_y.eval(session=tf.Session())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "df = pd.DataFrame(out-test)"
   ]
  },
  {
   "source": [
    "- EPOCH1: ACCURACY IS 10.09 %  \n",
    "  EPOCH2: ACCURACY IS  9.74 %"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ACCURACY IS 9.74 %\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "for i in range(len(df)):\n",
    "    temp=df.iloc[i].values\n",
    "    for j in temp:\n",
    "        if (j==-1): \n",
    "            count+=1\n",
    "\n",
    "print(\"ACCURACY IS {:.2f} %\".format(100-count/len(df)*100))"
   ]
  },
  {
   "source": [
    "## 1번 서술\n",
    "- 상황: training loss가 0.5이하로 떨어지지 않고 수렴  \n",
    "- 원인 예측: 학습이 언더피팅 되어 수렴하고 있고, 모델이 데이터의 특징을 학습하고 있지 못하여 발생 (Low Variance, High Bias)  \n",
    "- 해결 방안: 언더피팅을 방지하기 위한 방법 접근 (Bias 낮추기)  \n",
    "    1)모델의 파라미터 개수를 증가하여, 모델의 복잡도를 증가시켜 데이터가 잘 학습될 수 있도록 한다.  \n",
    "    2) 인풋 데이터의 Normalization을 수행하여, Feed data의  Scale을 동일한 수준에서 수행하고, 모델을 학습시킨다.  \n",
    "    3) 러닝레이트 스케쥴링, Epoch가 진행됨에 따라 점직적으로 러닝레이트를 감소시켜 모델을 학습시킨다.  \n",
    "\n",
    "## 2번 서술\n",
    "- 문제: Training 데이터에 오버피팅 되어 (High Variance, Low Bias), Validation에서는 제대로 된 예측이 안되고 있음을 확인할 수 있다. 해당 모델을 사용할 경우, 새로운 데이터에서 제대로된 예측이 되지 않는다.   \n",
    "- 해결방법: 오버피팅 방지하기 위한 방법 접근(Variance 낮추기)  \n",
    "    1) Cost function을 기존 에러 제곱만을 쓰고 있다면, weighting parameter 의 값도 추가하는, Regularization을 적용한다. 이렇게 하면 Variance가 낮아져, 오버피팅을 방지할 수 있다. (L1-Regular, L2-Regular 등)  \n",
    "    2) Dropout 적용: 오버피팅이 되는 것을 방지하기 위해, 뉴럴 노드의 학습 과정에서 random하게 dropout 시켜, 오버피팅을 방지할 수 있다.    \n",
    "    3) Neural Layer 의 파라미터 개수 줄이기: 파라미터의 개수를 줄여, 모델의 복잡성을 낮춰 Variance 를 감소시켜 오버피팅을 방지할 수 있다.  \n",
    "\n",
    "## 3번 서술\n",
    "- 문제 원인: 모델 Feed 데이터의 형태가 Conv Layer의 인풋 데이터 사이즈 맞지 않기 때문에 위와 같은 에러가 발생하였다. 따라서, 이를 해결하기 위해 Feed Data의 shape을 아래와 같이 변경해준다.\n",
    "- 추가할 코드:   \n",
    "```python\n",
    "    X_train = X_train.reshape((X_train.shape[0],X_train.shape[1],X_train.shape[2],1))  \n",
    "    X_test = X_test.reshape((X_test.shape[0],X_test.shape[1],X_test.shape[2],1))  \n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 끝"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}