{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# KAGGLE: Natural Language Processing with Diaster Tweets\n",
    "AUTHOR: SungwookLE  \n",
    "DATE: '21.7/5  \n",
    "\n",
    "### Competition Description\n",
    "\n",
    " It’s not always clear whether a person’s words are actually announcing a disaster. [This tweet](https://storage.googleapis.com/kaggle-media/competitions/tweet_screenshot.png) explicitly uses the word “ABLAZE” but means it metaphorically. This is clear to a human right away, especially with the visual aid. But it’s less clear to a machine.  \n",
    " In this competition, you’re challenged to build a machine learning model that predicts which Tweets are about real disasters and which one’s aren’t. You’ll have access to a dataset of 10,000 tweets that were hand classified. If this is your first time working on an NLP problem, we've created a [quick tutorial](https://www.kaggle.com/philculliton/nlp-getting-started-tutorial) to get you up and running. Disclaimer: The dataset for this competition contains text that may be considered profane, vulgar, or offensive.  \n",
    " Another [reference](https://www.kaggle.com/andreshg/nlp-glove-bert-tf-idf-lstm-explained#7.-LSTM) is here.  \n",
    "\n",
    "### DATA\n",
    "#### 1) What am I predicting\n",
    "- Predict whether a given tweet is about a real diaster or not. If so, predict a `1`, If not, predict a `0`.  \n",
    "\n",
    "#### 2) Columns\n",
    "- id - a unique identifier for each tweet\n",
    "- text - the text of the tweet\n",
    "- location - the location the tweet was sent from (may be blank)\n",
    "- keyword - a particular keyword from the tweet (may be blank)\n",
    "- target - in train.csv only, this denotes whether a tweet is about a real disaster (1) or not (0)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Before Starting, NLP Tutorial\n",
    "Natural Language Processing - is shorthand for a wide array of techniques designed to help machines learn from text. Natural Language Processing powers everything from chatbots to search engines, and is used in diverse tasks like sentiment analysis and machine translation.  \n",
    "\n",
    "In this tutorial we'll look at this competition's dataset, use a simple techniques to process it, build a machine learning model, and submit predictions for a score!\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import feature_extraction, linear_model, model_selection, preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"input/train.csv\")\n",
    "test_df = pd.read_csv(\"input/test.csv\")"
   ]
  },
  {
   "source": [
    "#### A quick look at out data\n",
    "Let's look at our data... first, an example of what is NOT a disaster twwet"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'I love fruits'"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "train_df.loc[train_df[\"target\"] == 0 ]['text'].values[1]"
   ]
  },
  {
   "source": [
    "And one that is:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Forest fire near La Ronge Sask. Canada'"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "train_df.loc[train_df[\"target\"] == 1 ]['text'].values[1]"
   ]
  },
  {
   "source": [
    "#### Building vectors\n",
    "The theory behind the model we'll build in this notebook is pretty simple: the words contained in each tweet are a good indicator of wheter they're about a real disaster or not (this is not entirely correct, but it's a great place to start)\n",
    "\n",
    "We'll use scikit-learn's `CountVectorizer` to count the words in each tweet and turn them into data our machine learning model can process.  \n",
    "\n",
    "Note: a `vector` is, in this context, a set of numbers that a machine learning model can work with. We'll look at one in just a second."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = feature_extraction.text.CountVectorizer()\n",
    "# let's get counts for the first 5 tweets in the data\n",
    "example_train_vectors = count_vectorizer.fit_transform(train_df[\"text\"][0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1, 54)\n[[0 0 0 1 1 1 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0\n  0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "# we use .todense() here bacause these vectors are \"sparse\" (only non-zero elements are kept to save space)\n",
    "print(example_train_vectors[0].todense().shape)\n",
    "print(example_train_vectors[0].todense())"
   ]
  },
  {
   "source": [
    "The above tells us that:\n",
    "1. There are 54 unique words (or \"tokens\") in the first five tweets.  \n",
    "2. The first tweets contains only some of those unique tokens - all of the non-zero counts above are the tokens that DO exist in the first tweet.\n",
    "\n",
    "Now let's create vectors for all of our tweets."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = count_vectorizer.fit_transform(train_df[\"text\"])\n",
    "\n",
    "# note that we're NOT using .fit_transform() here. Using just .transform() makes sure\n",
    "# that the tokens in the train vectors are the only ones mapped to the test vectors - i.e. that the train and test vectors use the same set of tokens.\n",
    "test_vectors = count_vectorizer.transform(test_df[\"text\"])"
   ]
  },
  {
   "source": [
    "#### Our model\n",
    "As we mentioned above, we think the words contained in each tweet are a good indicator of whether they're about a real disaster or not. The presence of particular word (or set of words) in a tweet might link directly to whether or not that tweet is real.  \n",
    "What we're assuming here is a linear connection. So let's build a linear model and see!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our vectors are really big, so we want to push our model's weights\n",
    "# toward 0 without completely discounting different words - ridge regression\n",
    "# is a good way to do this.\n",
    "\n",
    "clf = linear_model.RidgeClassifier()"
   ]
  },
  {
   "source": [
    "Let's test our model and see how well it does on the training data. For this we'll use `cross-validation` - where we train on a portion of the known data, then validate it with the rest. If we do this several times (with different portions) we can get a good idea for how a particular model or method performs.  \n",
    "The metric for this competition is F1, so let's use that here"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.59421842, 0.56498283, 0.64113893])"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "scores = model_selection.cross_val_score(clf, train_vectors, train_df['target'], cv=3, scoring=\"f1\")\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = linear_model.LogisticRegression(penalty='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.6387547 , 0.61347869, 0.68350669])"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "scores = model_selection.cross_val_score(clf, train_vectors, train_df['target'], cv=3, scoring=\"f1\")\n",
    "scores"
   ]
  },
  {
   "source": [
    "The above scores aren't terrible! It looks like our assumption will score roughly 0.65 on the learderboard, There are lots of ways to potentially improve on this (TFIDF, LSA, LSTM / RNNs, the list is long!) - give any of then a shot!  \n",
    "In the meantime, let's do predictions on our training sets and build a submission for the competition."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "clf.fit(train_vectors, train_df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('input/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission['target'] = clf.predict(test_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   id  target\n",
       "0   0       1\n",
       "1   2       1\n",
       "2   3       1\n",
       "3   9       0\n",
       "4  11       1"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv(\"output/submission.csv\", index=False)"
   ]
  },
  {
   "source": [
    "Now, in the viewer, you can submit the above file to the competition! Good luck!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "               text\n0           WHAT IS\n1  COUNT VECTORIZER\n2   SungwookLE TEST\n\n(1, 6)\n[[0 1 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "count_vectorizer = feature_extraction.text.CountVectorizer()\n",
    "a=[['WHAT IS'], ['COUNT VECTORIZER'], ['SungwookLE TEST']]\n",
    "a = pd.DataFrame(a, columns=['text'])\n",
    "print(a)\n",
    "print()\n",
    "example_vectors = count_vectorizer.fit_transform(a[\"text\"])\n",
    "# we use .todense() here bacause these vectors are \"sparse\" (only non-zero elements are kept to save space)\n",
    "print(example_vectors[0].todense().shape)\n",
    "print(example_vectors[0].todense())"
   ]
  }
 ]
}